{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature(df: pd.DataFrame) -> None:\n",
    "    df[\"air_process_diff\"] = abs(df[\"Air temperature [K]\"] - df[\"Process temperature [K]\"])\n",
    "    df[\"speed_power\"] = df['Rotational speed [rpm]'] * (2 * np.pi / 60) / (df['Rotational speed [rpm]'] * (2 * np.pi / 60) * df['Torque [Nm]'])\n",
    "    df['torque_power'] = df['Torque [Nm]'] / (df['Rotational speed [rpm]'] * (2 * np.pi / 60) * df['Torque [Nm]'])\n",
    "    df[\"tool_process\"] = df[\"Tool wear [min]\"] * df[\"Process temperature [K]\"]\n",
    "    df[\"temp_ratio\"] = df[\"Process temperature [K]\"] / df[\"Air temperature [K]\"]\n",
    "    df[\"product_id_num\"] = pd.to_numeric(df[\"Product ID\"].str.slice(start=1))\n",
    "    \n",
    "    df.drop(columns=\"Product ID\", inplace=True)\n",
    "    try:\n",
    "        df.drop(columns=\"id\", inplace=True)\n",
    "    except:\n",
    "        df.drop(columns=\"UDI\", inplace=True)\n",
    "    \n",
    "def identify_column_types(df: pd.DataFrame) -> tuple[list, list, list]:\n",
    "    num_cols = df.select_dtypes(\"float\").columns.tolist()\n",
    "    int_cols = df.select_dtypes(\"integer\").columns.tolist()\n",
    "    cat_cols = df.select_dtypes(\"object\").columns.tolist()\n",
    "    \n",
    "    return num_cols, int_cols, cat_cols\n",
    "\n",
    "def load_data(path):\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    create_feature(df)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/raw/train.csv\"\n",
    "test_path = \"../data/raw/test.csv\"\n",
    "origin_path = \"../data/raw/machine failure.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Machine failure'\n",
    "\n",
    "num_cols = [\n",
    "    'Air temperature [K]',\n",
    "    'Process temperature [K]',\n",
    "    'Rotational speed [rpm]',\n",
    "    'Torque [Nm]',\n",
    "    'Tool wear [min]'\n",
    "]\n",
    "\n",
    "binary_cols = [\n",
    "    'TWF',\n",
    "    'HDF',\n",
    "    'PWF',\n",
    "    'OSF',\n",
    "    'RNF'\n",
    "]\n",
    "\n",
    "# cat_cols = 'Type'\n",
    "cat_cols = ['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_data(train_path)\n",
    "df_test = load_data(test_path)\n",
    "df_origin = load_data(origin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_origin], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df[\"encoded_\" + col] = le.fit_transform(df[col])\n",
    "    \n",
    "df.drop(cat_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moon/.pyenv/versions/3.10.12/envs/comparison-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\n",
    "\n",
    "X, y = df.drop(\"Machine failure\", axis=1), df[\"Machine failure\"]\n",
    "X.columns = [re.sub(r\"[^a-zA-Z0-9_]+\", \"_\", col) for col in X.columns]\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.00362+0.00009\ttest-error:0.00367+0.00033\n",
      "[1]\ttrain-error:0.00362+0.00009\ttest-error:0.00367+0.00033\n",
      "[2]\ttrain-error:0.00362+0.00009\ttest-error:0.00367+0.00033\n",
      "[3]\ttrain-error:0.00362+0.00009\ttest-error:0.00367+0.00033\n",
      "[4]\ttrain-error:0.00361+0.00009\ttest-error:0.00365+0.00033\n",
      "[5]\ttrain-error:0.00361+0.00009\ttest-error:0.00365+0.00033\n",
      "[6]\ttrain-error:0.00361+0.00009\ttest-error:0.00364+0.00034\n",
      "[7]\ttrain-error:0.00361+0.00009\ttest-error:0.00364+0.00033\n",
      "[8]\ttrain-error:0.00361+0.00008\ttest-error:0.00365+0.00034\n",
      "[9]\ttrain-error:0.00360+0.00008\ttest-error:0.00365+0.00035\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(data=X, label=y)\n",
    "param = {\"objective\": \"binary:logistic\"}\n",
    "num_round = 10\n",
    "res = xgb.cv(\n",
    "    param,\n",
    "    dtrain,\n",
    "    num_round,\n",
    "    nfold=5,\n",
    "    metrics={\"error\"},\n",
    "    seed=42,\n",
    "    callbacks=[xgb.callback.EvaluationMonitor(show_stdv=True)],\n",
    "    early_stopping_rounds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003621</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.000331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "0          0.003625         0.000091         0.003674        0.000327\n",
       "1          0.003625         0.000091         0.003674        0.000327\n",
       "2          0.003625         0.000091         0.003674        0.000327\n",
       "3          0.003621         0.000088         0.003667        0.000332\n",
       "4          0.003614         0.000087         0.003654        0.000332\n",
       "5          0.003613         0.000086         0.003654        0.000332\n",
       "6          0.003614         0.000087         0.003640        0.000343\n",
       "7          0.003609         0.000091         0.003640        0.000331\n",
       "8          0.003606         0.000083         0.003647        0.000344\n",
       "9          0.003597         0.000080         0.003647        0.000350"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "scores = cross_validate(\n",
    "    xgb_clf, X, y, cv=skf, scoring = \"roc_auc\", n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base ROCAUC: 0.96686\n"
     ]
    }
   ],
   "source": [
    "base_roc = scores[\"test_score\"].mean()\n",
    "print(f\"Base ROCAUC: {base_roc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_experiment(experiment_name):\n",
    "    \"\"\"\n",
    "    Retrieve the ID of an existing MLflow experiment or create a new one if it doesn't exist.\n",
    "\n",
    "    This function checks if an experiment with the given name exists within MLflow.\n",
    "    If it does, the function returns its ID. If not, it creates a new experiment\n",
    "    with the provided name and returns its ID.\n",
    "\n",
    "    Parameters:\n",
    "    Returns:\n",
    "    - str: ID of the existing or newly created MLflow experiment.\n",
    "    \"\"\"\n",
    "\n",
    "    if experiment := mlflow.get_experiment_by_name(experiment_name):\n",
    "        return experiment.experiment_id\n",
    "    else:\n",
    "        return mlflow.create_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = get_or_create_experiment(\"Test Experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'747810045357265472'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/moon/project/mlops-pm/notebooks/mlruns/747810045357265472', creation_time=1717573153708, experiment_id='747810045357265472', last_update_time=1717573153708, lifecycle_stage='active', name='Test Experiment', tags={}>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the current active MLflow experiment\n",
    "mlflow.set_experiment(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y, cv, scoring):\n",
    "    \n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # Perform CV\n",
    "    xgb_clf = xgb.XGBClassifier(**params, random_state=42, eval_metric=\"auc\", objective=\"binary:logistic\")\n",
    "    scores = cross_validate(xgb_clf, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    # Compute ROC\n",
    "    roc = scores[\"test_score\"].mean()\n",
    "\n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_correlation_with_demand(df, save_path=None):\n",
    "    \"\"\"\n",
    "    Plots the correlation of each variable in the dataframe with the 'demand' column.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing the data, including a 'demand' column.\n",
    "    - save_path (str, optional): Path to save the generated plot. If not specified, plot won't be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None (Displays the plot on a Jupyter window)\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute correlations between all variables and 'demand'\n",
    "    correlations = df.corr()[\"Machine failure\"].drop(\"Machine failure\").sort_values()\n",
    "\n",
    "    # Generate a color palette from red to green\n",
    "    colors = sns.diverging_palette(10, 130, as_cmap=True)\n",
    "    color_mapped = correlations.map(colors)\n",
    "\n",
    "    # Set Seaborn style\n",
    "    sns.set_style(\n",
    "        \"whitegrid\", {\"axes.facecolor\": \"#c2c4c2\", \"grid.linewidth\": 1.5}\n",
    "    )  # Light grey background and thicker grid lines\n",
    "\n",
    "    # Create bar plot\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    plt.barh(correlations.index, correlations.values, color=color_mapped)\n",
    "\n",
    "    # Set labels and title with increased font size\n",
    "    plt.title(\"Correlation with Machine failure\", fontsize=18)\n",
    "    plt.xlabel(\"Correlation Coefficient\", fontsize=16)\n",
    "    plt.ylabel(\"Variable\", fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.grid(axis=\"x\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot if save_path is specified\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format=\"png\", dpi=600)\n",
    "\n",
    "    # prevent matplotlib from displaying the chart every time we call this function\n",
    "    plt.close(fig)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Test the function\n",
    "correlation_plot = plot_correlation_with_demand(df, save_path=\"correlation_plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_feature_importance(model, booster):\n",
    "    \"\"\"\n",
    "    Plots feature importance for an XGBoost model.\n",
    "\n",
    "    Args:\n",
    "    - model: A trained XGBoost model\n",
    "\n",
    "    Returns:\n",
    "    - fig: The matplotlib figure object\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    importance_type = \"weight\" if booster == \"gblinear\" else \"gain\"\n",
    "    xgb.plot_importance(\n",
    "        model,\n",
    "        importance_type=importance_type,\n",
    "        ax=ax,\n",
    "        title=f\"Feature Importance based on {importance_type}\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(model, dvalid, valid_y, save_path=None):\n",
    "    \"\"\"\n",
    "    Plots the residuals of the model predictions against the true values.\n",
    "\n",
    "    Args:\n",
    "    - model: The trained XGBoost model.\n",
    "    - dvalid (xgb.DMatrix): The validation data in XGBoost DMatrix format.\n",
    "    - valid_y (pd.Series): The true values for the validation set.\n",
    "    - save_path (str, optional): Path to save the generated plot. If not specified, plot won't be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None (Displays the residuals plot on a Jupyter window)\n",
    "    \"\"\"\n",
    "\n",
    "    # Predict using the model\n",
    "    preds = model.predict(dvalid)\n",
    "\n",
    "    # Calculate residuals\n",
    "    residuals = valid_y - preds\n",
    "\n",
    "    # Set Seaborn style\n",
    "    sns.set_style(\"whitegrid\", {\"axes.facecolor\": \"#c2c4c2\", \"grid.linewidth\": 1.5})\n",
    "\n",
    "    # Create scatter plot\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(valid_y, residuals, color=\"blue\", alpha=0.5)\n",
    "    plt.axhline(y=0, color=\"r\", linestyle=\"-\")\n",
    "\n",
    "    # Set labels, title and other plot properties\n",
    "    plt.title(\"Residuals vs True Values\", fontsize=18)\n",
    "    plt.xlabel(\"True Values\", fontsize=16)\n",
    "    plt.ylabel(\"Residuals\", fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.grid(axis=\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot if save_path is specified\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format=\"png\", dpi=600)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.close(fig)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def champion_callback(study, frozen_trial):\n",
    "    \"\"\"\n",
    "    Logging callback that will report when a new trial iteration improves upon existing\n",
    "    best trial values.\n",
    "\n",
    "    Note: This callback is not intended for use in distributed computing systems such as Spark\n",
    "    or Ray due to the micro-batch iterative implementation for distributing trials to a cluster's\n",
    "    workers or agents.\n",
    "    The race conditions with file system state management for distributed trials will render\n",
    "    inconsistent values with this callback.\n",
    "    \"\"\"\n",
    "\n",
    "    winner = study.user_attrs.get(\"winner\", None)\n",
    "\n",
    "    if study.best_value and winner != study.best_value:\n",
    "        study.set_user_attr(\"winner\", study.best_value)\n",
    "        if winner:\n",
    "            improvement_percent = (abs(winner - study.best_value) / study.best_value) * 100\n",
    "            print(\n",
    "                f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "                f\"{improvement_percent: .4f}% improvement\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Initial trial {frozen_trial.number} achieved value: {frozen_trial.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-10 19:13:19,948] A new study created in memory with name: no-name-b67e0067-7184-435e-a517-6d44601004aa\n",
      "[I 2024-06-10 19:13:27,899] Trial 0 finished with value: 0.9653722857917234 and parameters: {'n_estimators': 346, 'learning_rate': 0.0017369959842948907, 'max_depth': 9, 'subsample': 0.8433621584275277, 'colsample_bytree': 0.7245640879872735}. Best is trial 0 with value: 0.9653722857917234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial trial 0 achieved value: 0.9653722857917234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-10 19:13:36,151] Trial 1 finished with value: 0.9657935139488096 and parameters: {'n_estimators': 465, 'learning_rate': 0.003928436411782914, 'max_depth': 7, 'subsample': 0.7918667481293671, 'colsample_bytree': 0.6783794308138725}. Best is trial 1 with value: 0.9657935139488096.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 achieved value: 0.9657935139488096 with  0.0436% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-10 19:13:58,293] Trial 2 finished with value: 0.9633657113089076 and parameters: {'n_estimators': 1058, 'learning_rate': 0.15143468690321665, 'max_depth': 7, 'subsample': 0.7264839851454977, 'colsample_bytree': 0.5693424637866555}. Best is trial 1 with value: 0.9657935139488096.\n",
      "[I 2024-06-10 19:14:14,739] Trial 3 finished with value: 0.9645521222205723 and parameters: {'n_estimators': 770, 'learning_rate': 0.12851533764798612, 'max_depth': 7, 'subsample': 0.7383468663229358, 'colsample_bytree': 0.6454056929679579}. Best is trial 1 with value: 0.9657935139488096.\n",
      "[I 2024-06-10 19:14:21,170] Trial 4 finished with value: 0.9667030519123025 and parameters: {'n_estimators': 452, 'learning_rate': 0.009261204614790566, 'max_depth': 6, 'subsample': 0.7169852437128189, 'colsample_bytree': 0.6263143410744128}. Best is trial 4 with value: 0.9667030519123025.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 achieved value: 0.9667030519123025 with  0.0941% improvement\n",
      "log_tag-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moon/.pyenv/versions/3.10.12/envs/comparison-env/lib/python3.10/site-packages/mlflow/types/utils.py:394: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/home/moon/.pyenv/versions/3.10.12/envs/comparison-env/lib/python3.10/site-packages/mlflow/types/utils.py:394: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 2.49 s, total: 1min 43s\n",
      "Wall time: 1min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moon/.pyenv/versions/3.10.12/envs/comparison-env/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/moon/.pyenv/versions/3.10.12/envs/comparison-env/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"first_attempt\", nested=True):\n",
    "    # Create study that minimizes\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    \n",
    "    # Wrap the objective inside a lambda with the relevant arguments\n",
    "    # Pass additional arguments inside another function\n",
    "    func = lambda trial: objective(trial, X, y, cv=skf, scoring=\"roc_auc\")\n",
    "\n",
    "    # Start optimizing with 100 trials\n",
    "    study.optimize(func, n_trials=5, callbacks=[champion_callback])\n",
    "    \n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_metric(\"best_roc\", study.best_value)\n",
    "    \n",
    "    # Log tags\n",
    "    mlflow.set_tags(\n",
    "        tags={\n",
    "            \"project\": \"PM Project\",\n",
    "            \"optimizer_engine\": \"optuna\",\n",
    "            \"model_family\": \"xgboost\",\n",
    "            \"feature_set_version\": 1,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"log_tag-----\")\n",
    "    # Log a fit model instance\n",
    "    model = xgb.XGBClassifier(**study.best_params, random_state=42, eval_metric=\"auc\", objective=\"binary:logistic\")\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Log the correlation plot\n",
    "    mlflow.log_figure(figure=correlation_plot, artifact_file=\"correlation_plot.png\")\n",
    "\n",
    "    # Log the feature importances plot\n",
    "    importances = plot_feature_importance(model, booster=study.best_params.get(\"booster\"))\n",
    "    mlflow.log_figure(figure=importances, artifact_file=\"feature_importances.png\")\n",
    "\n",
    "    # Log the residuals plot\n",
    "    residuals = plot_residuals(model, X, y)\n",
    "    mlflow.log_figure(figure=residuals, artifact_file=\"residuals.png\")\n",
    "    \n",
    "    artifact_path = \"model\"\n",
    "    \n",
    "    mlflow.xgboost.log_model(\n",
    "        xgb_model=model,\n",
    "        artifact_path=artifact_path,\n",
    "        input_example=X.iloc[[0]],\n",
    "        model_format=\"ubj\",\n",
    "        metadata={\"model_data_version\": 1},\n",
    "    )\n",
    "\n",
    "    # Get the logged model uri so that we can load it from the artifact store\n",
    "    model_uri = mlflow.get_artifact_uri(artifact_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-05 16:29:22,810] A new study created in memory with name: no-name-95f7cafb-3d6b-4588-ba31-47e182bae1fb\n",
      "[I 2024-06-05 16:29:32,903] Trial 0 finished with value: 0.9652396862289561 and parameters: {'n_estimators': 617, 'learning_rate': 0.001399771218293194, 'max_depth': 5, 'subsample': 0.5392642859683296, 'colsample_bytree': 0.5448109404935677}. Best is trial 0 with value: 0.9652396862289561.\n",
      "[I 2024-06-05 16:29:37,592] Trial 1 finished with value: 0.9586865578546299 and parameters: {'n_estimators': 230, 'learning_rate': 0.0012947107883542277, 'max_depth': 6, 'subsample': 0.7140267115610769, 'colsample_bytree': 0.8811867895750225}. Best is trial 0 with value: 0.9652396862289561.\n",
      "[I 2024-06-05 16:30:00,890] Trial 2 finished with value: 0.9680068354092315 and parameters: {'n_estimators': 651, 'learning_rate': 0.009250240924955157, 'max_depth': 13, 'subsample': 0.9692860161962089, 'colsample_bytree': 0.9972574494334845}. Best is trial 2 with value: 0.9680068354092315.\n",
      "[I 2024-06-05 16:30:20,109] Trial 3 finished with value: 0.9653257326492758 and parameters: {'n_estimators': 495, 'learning_rate': 0.0495259924506139, 'max_depth': 14, 'subsample': 0.7852801845017363, 'colsample_bytree': 0.7834661077923923}. Best is trial 2 with value: 0.9680068354092315.\n",
      "[I 2024-06-05 16:30:39,779] Trial 4 finished with value: 0.9708227503625879 and parameters: {'n_estimators': 959, 'learning_rate': 0.01253278960281304, 'max_depth': 7, 'subsample': 0.7544060353752393, 'colsample_bytree': 0.9822523112702799}. Best is trial 4 with value: 0.9708227503625879.\n",
      "[I 2024-06-05 16:30:57,588] Trial 5 finished with value: 0.9627977184166389 and parameters: {'n_estimators': 726, 'learning_rate': 0.18550497583401057, 'max_depth': 8, 'subsample': 0.568430256260942, 'colsample_bytree': 0.7327333245011257}. Best is trial 4 with value: 0.9708227503625879.\n",
      "[I 2024-06-05 16:31:24,330] Trial 6 finished with value: 0.9690618833857171 and parameters: {'n_estimators': 1011, 'learning_rate': 0.0021338867416954097, 'max_depth': 13, 'subsample': 0.670321636791009, 'colsample_bytree': 0.7237237176792849}. Best is trial 4 with value: 0.9708227503625879.\n",
      "[I 2024-06-05 16:31:27,714] Trial 7 finished with value: 0.9659831893683635 and parameters: {'n_estimators': 200, 'learning_rate': 0.23974529927553864, 'max_depth': 4, 'subsample': 0.6026616999105693, 'colsample_bytree': 0.6528948714103515}. Best is trial 4 with value: 0.9708227503625879.\n",
      "[I 2024-06-05 16:31:32,995] Trial 8 finished with value: 0.9650630507828091 and parameters: {'n_estimators': 295, 'learning_rate': 0.0011105925957821965, 'max_depth': 8, 'subsample': 0.5792717071825775, 'colsample_bytree': 0.7957729887393539}. Best is trial 4 with value: 0.9708227503625879.\n",
      "[I 2024-06-05 16:31:44,432] Trial 9 finished with value: 0.9648891362910186 and parameters: {'n_estimators': 951, 'learning_rate': 0.0018293518576030167, 'max_depth': 5, 'subsample': 0.75129352299462, 'colsample_bytree': 0.6151978074362927}. Best is trial 4 with value: 0.9708227503625879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.18 s, sys: 1.31 s, total: 3.49 s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base ROCAUC: 0.96686\n",
      "Optimized ROCAUC: 0.97082\n"
     ]
    }
   ],
   "source": [
    "print(f\"Base ROCAUC: {base_roc:.5f}\")\n",
    "print(f\"Optimized ROCAUC: {study.best_value:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "\tn_estimators: 959\n",
      "\tlearning_rate: 0.01253278960281304\n",
      "\tmax_depth: 7\n",
      "\tsubsample: 0.7544060353752393\n",
      "\tcolsample_bytree: 0.9822523112702799\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/comparison-env/lib/python3.10/site-packages/optuna/visualization/_plotly_imports.py:7\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m try_import() \u001b[38;5;28;01mas\u001b[39;00m _imports:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m plotly_version\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_optimization_history\n\u001b[1;32m      3\u001b[0m plotly_config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticPlot\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m----> 5\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mplot_optimization_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow(config\u001b[38;5;241m=\u001b[39mplotly_config)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/comparison-env/lib/python3.10/site-packages/optuna/visualization/_optimization_history.py:222\u001b[0m, in \u001b[0;36mplot_optimization_history\u001b[0;34m(study, target, target_name, error_bar)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_optimization_history\u001b[39m(\n\u001b[1;32m    173\u001b[0m     study: Study \u001b[38;5;241m|\u001b[39m Sequence[Study],\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m     error_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgo.Figure\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Plot optimization history of all trials in a study.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m        A :class:`plotly.graph_objects.Figure` object.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[43m_imports\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     info_list \u001b[38;5;241m=\u001b[39m _get_optimization_history_info_list(study, target, target_name, error_bar)\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_optimization_history_plot(info_list, target_name)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/comparison-env/lib/python3.10/site-packages/optuna/_imports.py:89\u001b[0m, in \u001b[0;36m_DeferredImportExceptionContextManager.check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     exc_value, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc_value\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "plotly_config = {\"staticPlot\": True}\n",
    "\n",
    "fig = plot_optimization_history(study)\n",
    "fig.show(config=plotly_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comparison-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
